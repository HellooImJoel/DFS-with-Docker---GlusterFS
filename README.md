# üß© Sistema de Archivos Distribuido con Docker y GlusterFS

## üìò Gu√≠a Completa de Implementaci√≥n

---

## üìã √çndice

1. [Descripci√≥n General](#descripci√≥n-general)
2. [Requisitos Previos](#requisitos-previos)
3. [Fundamentos Te√≥ricos](#fundamentos-te√≥ricos)
4. [Arquitectura del Sistema](#arquitectura-del-sistema)
5. [Implementaci√≥n Paso a Paso](#implementaci√≥n-paso-a-paso)
6. [Pruebas y Verificaci√≥n](#pruebas-y-verificaci√≥n)
7. [Resoluci√≥n de Problemas](#resoluci√≥n-de-problemas)
8. [Conclusiones](#conclusiones)

---

## üìò Descripci√≥n General

Este proyecto implementa un **Sistema de Archivos Distribuido (DFS)** utilizando contenedores Docker para simular m√∫ltiples nodos de red y GlusterFS como sistema de archivos distribuido.

### Objetivos

- ‚úÖ Comprender la arquitectura de un sistema de archivos distribuido
- ‚úÖ Simular un entorno de red distribuida con Docker
- ‚úÖ Configurar un volumen compartido y replicado con GlusterFS
- ‚úÖ Montar el volumen distribuido en un cliente
- ‚úÖ Evaluar la consistencia, replicaci√≥n y tolerancia a fallos

---

## üîß Requisitos Previos

### Software necesario

- **Docker Desktop** instalado y en ejecuci√≥n
- **Docker Compose** (incluido en Docker Desktop)
- Terminal o l√≠nea de comandos
- Editor de texto (VS Code, Notepad++, etc.)

### Conocimientos b√°sicos

- Comandos b√°sicos de terminal/bash
- Conceptos b√°sicos de Docker
- Nociones de sistemas de archivos

---

## üß† Fundamentos Te√≥ricos

### ¬øQu√© es un Sistema de Archivos Distribuido?

Un **DFS (Distributed File System)** permite que varios equipos (nodos) compartan y accedan de forma concurrente a archivos almacenados en distintos puntos de una red, manteniendo la transparencia de acceso.

### Caracter√≠sticas clave

- **Transparencia de localizaci√≥n**: El usuario accede a los archivos sin saber en qu√© nodo est√°n almacenados
- **Replicaci√≥n y tolerancia a fallos**: El sistema mantiene copias sincronizadas de los datos
- **Escalabilidad**: Se pueden agregar nodos para aumentar capacidad o disponibilidad
- **Seguridad y consistencia**: Garantiza que los datos sean coherentes en toda la red

### ¬øQu√© es GlusterFS?

GlusterFS es un sistema de archivos distribuido moderno, basado en el concepto de "vol√∫menes distribuidos y replicados", que agrupa m√∫ltiples servidores en un mismo sistema l√≥gico de archivos.

### ¬øQu√© es Docker?

Docker es una plataforma que permite crear "contenedores" - entornos virtuales aislados que act√∫an como servidores independientes, pero comparten el kernel del sistema operativo host.

---

## üèóÔ∏è Arquitectura del Sistema

### Escenario: DataLink Corp

La empresa DataLink Corp necesita garantizar el acceso compartido a documentos y recursos por parte de distintos servidores regionales.

### Componentes del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     NODE1       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ     NODE2       ‚îÇ
‚îÇ  (Servidor A)   ‚îÇ         ‚îÇ  (Servidor B)   ‚îÇ
‚îÇ   - Almacena    ‚îÇ         ‚îÇ   - R√©plica     ‚îÇ
‚îÇ   - Sincroniza  ‚îÇ         ‚îÇ   - Sincroniza  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                           ‚îÇ
         ‚îÇ    Red GlusterNet         ‚îÇ
         ‚îÇ                           ‚îÇ
         ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫   CLIENT    ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ  (Usuario)  ‚îÇ
               ‚îÇ  Accede a   ‚îÇ
               ‚îÇ  archivos   ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Descripci√≥n de nodos

- **Node1**: Servidor de almacenamiento A (nodo primario)
- **Node2**: Servidor de almacenamiento B (r√©plica sincronizada)
- **Client**: Nodo cliente que monta y accede al sistema de archivos distribuido

---

## üöÄ Implementaci√≥n Paso a Paso

### PASO 1: Crear la estructura del proyecto

```bash
# Crear directorio del proyecto
mkdir dfs-lab
cd dfs-lab

# Crear subdirectorio para pruebas
mkdir pruebas
```

Tu estructura debe quedar as√≠:

```
dfs-lab/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ pruebas/
```

---

### PASO 2: Crear el archivo docker-compose.yml

Crea un archivo llamado `docker-compose.yml` con el siguiente contenido:

```yaml
services:
  node1:
    image: gluster/gluster-centos:latest
    container_name: node1
    privileged: true
    networks:
      - glusternet
    volumes:
      - data1:/data/brick1
    hostname: node1
    command: /bin/bash -c "glusterd && tail -f /dev/null"

  node2:
    image: gluster/gluster-centos:latest
    container_name: node2
    privileged: true
    networks:
      - glusternet
    volumes:
      - data2:/data/brick1
    hostname: node2
    command: /bin/bash -c "glusterd && tail -f /dev/null"

  client:
    image: almalinux:9
    container_name: client
    privileged: true
    networks:
      - glusternet
    depends_on:
      - node1
      - node2
    tty: true
    stdin_open: true

networks:
  glusternet:
    driver: bridge

volumes:
  data1:
  data2:
```

#### Explicaci√≥n de la configuraci√≥n

- **image**: Im√°genes Docker oficiales (gluster-centos para nodos, almalinux para cliente)
- **privileged**: Necesario para que GlusterFS funcione correctamente
- **networks**: Red virtual compartida entre contenedores
- **volumes**: Almacenamiento persistente para cada nodo
- **command**: Inicia autom√°ticamente el demonio de GlusterFS

---

### PASO 3: Inicializar el entorno

```bash
# Levantar todos los servicios
docker-compose up -d

# Esperar a que los contenedores arranquen
sleep 10

# Verificar que est√©n corriendo
docker ps
```

**Resultado esperado:**

```
CONTAINER ID   NAME      IMAGE                          STATUS
xxxxx          node1     gluster/gluster-centos:latest  Up
xxxxx          node2     gluster/gluster-centos:latest  Up
xxxxx          client    almalinux:9                    Up
```

---

### PASO 4: Verificar que glusterd est√© corriendo

```bash
# Verificar node1
docker exec node1 ps aux | grep glusterd

# Verificar node2
docker exec node2 ps aux | grep glusterd
```

Deber√≠as ver procesos `glusterd` activos en ambos nodos.

---

### PASO 5: Configurar el cl√∫ster GlusterFS

```bash
# Conectar node1 con node2 (formar el cl√∫ster)
docker exec -it node1 gluster peer probe node2

# Verificar el estado del cl√∫ster
docker exec -it node1 gluster peer status
```

**Resultado esperado:**

```
Number of Peers: 1

Hostname: node2
Uuid: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
State: Peer in Cluster (Connected)
```

‚úÖ Esto confirma que ambos nodos est√°n conectados y forman un cl√∫ster.

---

### PASO 6: Crear el volumen distribuido y replicado

```bash
# Crear el volumen con r√©plica en 2 nodos
docker exec -it node1 gluster volume create datavolume replica 2 transport tcp node1:/data/brick1 node2:/data/brick1 force

# Iniciar el volumen
docker exec -it node1 gluster volume start datavolume

# Ver informaci√≥n del volumen
docker exec -it node1 gluster volume info
```

**Resultado esperado:**

```
Volume Name: datavolume
Type: Replicate
Volume ID: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 2 = 2
Transport-type: tcp
Bricks:
Brick1: node1:/data/brick1
Brick2: node2:/data/brick1
```

#### Explicaci√≥n

- **Type: Replicate**: Los datos se replican en ambos nodos
- **Number of Bricks: 1 x 2 = 2**: Un volumen con 2 r√©plicas
- **Status: Started**: El volumen est√° activo y funcionando

---

### PASO 7: Instalar GlusterFS en el cliente

```bash
# Entrar al contenedor client
docker exec -it client bash
```

Ahora est√°s **dentro del contenedor**. El prompt cambiar√° a:

```
[root@client /]#
```

Ejecuta:

```bash
# Actualizar el sistema (opcional pero recomendado)
dnf update -y

# Instalar el cliente GlusterFS
dnf install -y glusterfs glusterfs-fuse

# Verificar la instalaci√≥n
glusterfs --version
```

**NO salgas del contenedor a√∫n**, contin√∫a en el siguiente paso.

---

### PASO 8: Montar el volumen en el cliente

**Dentro del contenedor client** (donde a√∫n est√°s), ejecuta:

```bash
# Crear el punto de montaje
mkdir -p /mnt/dfs

# Montar el volumen GlusterFS
mount -t glusterfs node1:/datavolume /mnt/dfs

# Verificar el montaje
df -hT | grep gluster
```

**Resultado esperado:**

```
node1:/datavolume  fuse.glusterfs  1007G  14G  953G  2% /mnt/dfs
```

‚úÖ El volumen est√° correctamente montado en `/mnt/dfs`.

#### Explicaci√≥n del comando mount

- `-t glusterfs`: Tipo de sistema de archivos
- `node1:/datavolume`: Servidor y nombre del volumen
- `/mnt/dfs`: Punto de montaje local

---

### PASO 9: Realizar pruebas de escritura/lectura

**Dentro del contenedor client**, ejecuta:

```bash
# Crear archivo de prueba
echo "Hola DFS Distribuido!" > /mnt/dfs/prueba.txt

# Leer el archivo
cat /mnt/dfs/prueba.txt

# Crear m√°s archivos
echo "Este es el archivo 2" > /mnt/dfs/archivo2.txt
echo "Este es el archivo 3" > /mnt/dfs/archivo3.txt

# Crear una carpeta con contenido
mkdir /mnt/dfs/documentos
echo "Documento interno" > /mnt/dfs/documentos/doc1.txt

# Listar todos los archivos
ls -la /mnt/dfs/
ls -la /mnt/dfs/documentos/
```

Ahora **sal del contenedor**:

```bash
exit
```

---

## üß™ Pruebas y Verificaci√≥n

### PRUEBA 1: Verificar replicaci√≥n entre nodos

**Desde tu terminal (fuera de los contenedores):**

```bash
# Verificar archivos en node1
docker exec node1 ls -la /data/brick1/

# Leer contenido en node1
docker exec node1 cat /data/brick1/prueba.txt

# Verificar archivos en node2
docker exec node2 ls -la /data/brick1/

# Leer contenido en node2
docker exec node2 cat /data/brick1/prueba.txt
```

‚úÖ **Los archivos deben estar id√©nticos en ambos nodos**. Esto confirma que la replicaci√≥n funciona correctamente.

---

### PRUEBA 2: Tolerancia a fallos (Detener node1)

```bash
# Apagar el nodo1
docker stop node1

# Entrar al cliente
docker exec -it client bash

# Intentar leer archivos (desde dentro del client)
cat /mnt/dfs/prueba.txt
ls /mnt/dfs/

# Crear un nuevo archivo con node1 apagado
echo "Archivo creado sin node1" > /mnt/dfs/nuevo.txt

# Salir
exit
```

‚úÖ **El sistema debe seguir funcionando** porque node2 tiene todas las r√©plicas.

---

### PRUEBA 3: Recuperaci√≥n del nodo

```bash
# Volver a encender node1
docker start node1

# Esperar a que se reconecte
sleep 10

# Verificar reconexi√≥n
docker exec -it node1 gluster peer status

# Verificar que el archivo nuevo se replic√≥
docker exec node1 cat /data/brick1/nuevo.txt
```

‚úÖ GlusterFS **sincroniza autom√°ticamente** los cambios cuando el nodo vuelve.

---

### PRUEBA 4: Escritura concurrente

```bash
# Abrir dos terminales

# Terminal 1 - Entrar al client
docker exec -it client bash
echo "Escritura desde terminal 1" >> /mnt/dfs/concurrente.txt

# Terminal 2 - Escribir directamente en node1
docker exec -it node1 bash
echo "Escritura desde node1" >> /data/brick1/concurrente.txt

# Leer el archivo desde client
docker exec client cat /mnt/dfs/concurrente.txt
```

Observar c√≥mo GlusterFS maneja la sincronizaci√≥n.

---

### PRUEBA 5: Medici√≥n de rendimiento

```bash
# Entrar al client
docker exec -it client bash

# Probar velocidad de escritura (crear archivo de 100MB)
dd if=/dev/zero of=/mnt/dfs/test.img bs=1M count=100 conv=fdatasync

# Probar velocidad de lectura
dd if=/mnt/dfs/test.img of=/dev/null bs=1M

# Salir
exit
```

Documentar los tiempos obtenidos.

---

## üîç Guardar Logs y Resultados

```bash
# Crear directorio de pruebas si no existe
mkdir -p pruebas

# Guardar logs de node1
docker logs node1 > pruebas/logs-node1.txt

# Guardar logs de node2
docker logs node2 > pruebas/logs-node2.txt

# Guardar informaci√≥n del volumen
docker exec node1 gluster volume info > pruebas/volumen-info.txt

# Guardar estado del cl√∫ster
docker exec node1 gluster peer status > pruebas/peer-status.txt

# Guardar lista de archivos replicados
docker exec node1 ls -laR /data/brick1/ > pruebas/archivos-node1.txt
docker exec node2 ls -laR /data/brick1/ > pruebas/archivos-node2.txt
```

---

## üõ†Ô∏è Resoluci√≥n de Problemas

### Problema 1: glusterd no est√° corriendo

**S√≠ntoma:**
```
Connection failed. Please check if gluster daemon is operational.
```

**Soluci√≥n:**
```bash
docker exec -d node1 glusterd
docker exec -d node2 glusterd
sleep 5
```

---

### Problema 2: Error al montar el volumen

**S√≠ntoma:**
```
Mount failed. Please check the log file for more details.
```

**Soluci√≥n:**
```bash
# Verificar que el volumen est√© activo
docker exec node1 gluster volume status datavolume

# Si est√° detenido, iniciarlo
docker exec node1 gluster volume start datavolume

# Reintentar montaje
docker exec -it client mount -t glusterfs node1:/datavolume /mnt/dfs
```

---

### Problema 3: Contenedores no se comunican

**S√≠ntoma:** Los nodos no pueden conectarse entre s√≠.

**Soluci√≥n:**
```bash
# Verificar que est√©n en la misma red
docker network inspect dfs-lab_glusternet

# Verificar conectividad
docker exec node1 ping -c 3 node2
docker exec node2 ping -c 3 node1
```

---

### Problema 4: Archivos no se replican

**Soluci√≥n:**
```bash
# Ver estado detallado del volumen
docker exec node1 gluster volume status datavolume detail

# Verificar que ambos bricks est√©n online
docker exec node1 gluster volume heal datavolume info

# Forzar sincronizaci√≥n
docker exec node1 gluster volume heal datavolume full
```

---

## üéØ Comandos √ötiles de Referencia

### Gesti√≥n de contenedores

```bash
# Ver contenedores activos
docker ps

# Ver todos los contenedores
docker ps -a

# Ver logs de un contenedor
docker logs node1

# Reiniciar un contenedor
docker restart node1

# Detener todos los servicios
docker-compose down

# Iniciar todos los servicios
docker-compose up -d

# Reconstruir contenedores
docker-compose up -d --build
```

### Gesti√≥n de vol√∫menes Docker

```bash
# Listar vol√∫menes
docker volume ls

# Inspeccionar un volumen
docker volume inspect dfs-lab_data1

# Eliminar vol√∫menes no usados
docker volume prune
```

### Comandos GlusterFS

```bash
# Ver estado del cl√∫ster
docker exec node1 gluster peer status

# Ver informaci√≥n del volumen
docker exec node1 gluster volume info

# Ver estado detallado del volumen
docker exec node1 gluster volume status datavolume detail

# Detener un volumen
docker exec node1 gluster volume stop datavolume

# Eliminar un volumen
docker exec node1 gluster volume delete datavolume

# Ver logs de GlusterFS
docker exec node1 tail -f /var/log/glusterfs/glusterd.log
```

---

## üí≠ An√°lisis Conceptual

### ¬øQu√© ocurre si ambos nodos fallan?

- **P√©rdida total de acceso**: Sin nodos disponibles, el cliente no puede acceder a los datos
- **Datos intactos**: Los datos permanecen en los vol√∫menes Docker persistentes
- **Recuperaci√≥n**: Al reiniciar los nodos, el sistema se recupera autom√°ticamente

### ¬øC√≥mo se asegura la consistencia entre copias?

GlusterFS utiliza:
- **Self-heal daemon**: Proceso que detecta y repara inconsistencias
- **Replicaci√≥n s√≠ncrona**: Las escrituras se confirman solo cuando se replican en todos los nodos
- **Metadata tracking**: Seguimiento de versiones y cambios

### ¬øQu√© mecanismos detectan fallos autom√°ticamente?

- **Heartbeat**: Comunicaci√≥n peri√≥dica entre nodos
- **Health checks**: Verificaci√≥n del estado de los servicios
- **Auto-heal**: Reparaci√≥n autom√°tica de archivos divididos (split-brain)

---

## üìä Conclusiones

### Ventajas de GlusterFS

‚úÖ **Alta disponibilidad**: Sin puntos √∫nicos de fallo  
‚úÖ **Escalabilidad horizontal**: F√°cil agregar m√°s nodos  
‚úÖ **Transparencia**: Los usuarios no perciben la distribuci√≥n  
‚úÖ **Integraci√≥n**: Compatible con contenedores, VMs y cloud  
‚úÖ **Open Source**: Gratuito y con comunidad activa  

### Desaf√≠os

‚ùå **Consistencia**: Requiere mecanismos de sincronizaci√≥n complejos  
‚ùå **Latencia**: En redes geogr√°ficamente distribuidas  
‚ùå **Complejidad**: Configuraci√≥n y mantenimiento en gran escala  
‚ùå **Split-brain**: Posibles conflictos en escrituras concurrentes  

### Casos de uso reales

- **Almacenamiento de medios**: Servidores de streaming
- **Big Data**: Hadoop, Analytics
- **Virtualizaci√≥n**: Almacenamiento compartido para VMs
- **Backups**: Replicaci√≥n geogr√°fica de datos cr√≠ticos
- **Cloud Storage**: Infraestructura de almacenamiento distribuido

---

## üöÄ Extensiones Avanzadas (Opcional)

### 1. Agregar un tercer nodo

Modificar `docker-compose.yml`:

```yaml
  node3:
    image: gluster/gluster-centos:latest
    container_name: node3
    privileged: true
    networks:
      - glusternet
    volumes:
      - data3:/data/brick1
    hostname: node3
    command: /bin/bash -c "glusterd && tail -f /dev/null"

volumes:
  data1:
  data2:
  data3:  # Agregar
```

Agregar al cl√∫ster:

```bash
docker exec node1 gluster peer probe node3
docker exec node1 gluster volume add-brick datavolume replica 3 node3:/data/brick1 force
```

### 2. Servidor web compartido

```bash
# Crear un contenedor nginx
docker run -d --name webserver \
  --network dfs-lab_glusternet \
  -v dfs-lab_data1:/usr/share/nginx/html:ro \
  -p 8080:80 \
  nginx

# Acceder en el navegador
# http://localhost:8080
```

### 3. Monitoreo con Prometheus

Integrar m√©tricas de GlusterFS con Prometheus y visualizar en Grafana.

### 4. Cifrado y autenticaci√≥n

```bash
# Habilitar autenticaci√≥n
docker exec node1 gluster volume set datavolume auth.allow 192.168.*

# Configurar SSL/TLS
docker exec node1 gluster volume set datavolume client.ssl on
docker exec node1 gluster volume set datavolume server.ssl on
```

---

## üìö Referencias y Recursos

### Documentaci√≥n oficial

- [GlusterFS Documentation](https://docs.gluster.org/)
- [Docker Documentation](https://docs.docker.com/)
- [Docker Compose Reference](https://docs.docker.com/compose/)

### Repositorios

- [GlusterFS GitHub](https://github.com/gluster/glusterfs)
- [Docker Gluster Images](https://hub.docker.com/r/gluster/gluster-centos)

### Tutoriales adicionales

- [GlusterFS Architecture](https://docs.gluster.org/en/latest/Quick-Start-Guide/Architecture/)
- [Docker Networking Guide](https://docs.docker.com/network/)
- [FUSE Filesystem](https://www.kernel.org/doc/html/latest/filesystems/fuse.html)

---

## ‚úÖ Checklist Final

Antes de finalizar el proyecto, verifica:

- [ ] Los 3 contenedores est√°n corriendo
- [ ] El cl√∫ster GlusterFS est√° formado (peer status OK)
- [ ] El volumen est√° creado y activo
- [ ] El volumen est√° montado en el cliente
- [ ] Los archivos se replican en ambos nodos
- [ ] La tolerancia a fallos funciona (probado)
- [ ] Logs guardados en carpeta `pruebas/`
- [ ] Capturas de pantalla tomadas
- [ ] Informe documentado

---

## üßπ Limpieza del entorno

Cuando termines el proyecto:

```bash
# Detener todos los contenedores
docker-compose down

# Eliminar vol√∫menes (CUIDADO: borra todos los datos)
docker volume rm dfs-lab_data1 dfs-lab_data2

# Eliminar im√°genes descargadas (opcional)
docker rmi gluster/gluster-centos:latest almalinux:9

# Limpiar sistema completo
docker system prune -a
```
